{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Funciones de Usuario (udfs)\n",
    "##   Apache Pig permite la ejecución de funciones escritas en Java, Jython (http://www.jython.org/index.html), JavaScript, Ruby, Groovy y Python. \n",
    "##   Información detallada de la ejecución de udfs en estos lenguajes puede ser obtenida en https://pig.apache.org/docs/latest/udf.html#python-udfs.\n",
    "##   Véase http://www.jython.org/index.html. Para su uso, el script de Python debe estar ubicado en el directorio de trabajo. Para poder usar Jython, hay dos opciones; \n",
    "##   en la primera se debe indicar la ubicación del inteprete en la variable PIG_CLASSPATH. En algunos casos es necesario establacer la variable PYTHONPATH para que \n",
    "##   Pig pueda compilar las udfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bigdata extension is already loaded. To reload it, use:\n",
      "  %reload_ext bigdata\n"
     ]
    }
   ],
   "source": [
    "%load_ext bigdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pig_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeout 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing udf.tsv\n"
     ]
    }
   ],
   "source": [
    "%%writefile udf.tsv\n",
    "A\tB\t1\n",
    "C\tD\t2\n",
    "E\tF\t3\n",
    "G\tH\t4\n",
    "I\tJ\t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -put udf.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing pigudf.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pigudf.py\n",
    "\n",
    "#from pig_util import outputSchema\n",
    "\n",
    "@outputSchema(\"as:int\")\n",
    "def square(num):\n",
    "    if num == None:\n",
    "        return None\n",
    "    return ((num) * (num))\n",
    "\n",
    "@outputSchema(\"word:chararray\")\n",
    "def concatenar(word1, word2):\n",
    "    return (word1 + word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --\n",
      " -- registra las funciones en el script `pigudf.py`.\n",
      " --\n",
      " REGISTER /Users/jdvelasq/jython2.7.0/jython.jar\n",
      "2019-12-07 13:45:43,627 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 101: file '/Users/jdvelasq/jython2.7.0/jython.jar' does not exist.\n",
      "Details at logfile: /datalake/pig_1575726330038.log\n",
      " REGISTER 'pigudf.py' using jython as myudf;\n",
      " u = LOAD 'udf.tsv' USING PigStorage()\n",
      "    AS (c1:CHARARRAY,\n",
      "        c2:CHARARRAY,\n",
      "        c3:INT);\n",
      " b = FOREACH u GENERATE myudf.concatenar(c1, c2), myudf.square(c3);\n",
      " DUMP b;\n",
      "2019-12-07 13:45:47,517 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 13:45:47,616 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2019-12-07 13:45:47,617 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2019-12-07 13:45:47,624 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication\n",
      "2019-12-07 13:45:49,383 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address\n",
      "2019-12-07 13:45:49,390 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 13:45:49,397 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2019-12-07 13:45:49,446 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2019-12-07 13:45:49,465 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2019-12-07 13:45:49,919 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2019-12-07 13:45:50,405 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1575720238556_0003\n",
      "2019-12-07 13:45:50,499 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2019-12-07 13:45:50,553 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1575720238556_0003\n",
      "2019-12-07 13:45:50,573 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://3b2346cc720b:8088/proxy/application_1575720238556_0003/\n",
      "2019-12-07 13:46:05,686 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 13:46:05,692 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 13:46:05,803 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 13:46:05,807 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 13:46:05,826 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2019-12-07 13:46:05,827 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 13:46:05,830 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 13:46:05,874 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 13:46:05,877 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 13:46:05,899 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 13:46:05,902 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 13:46:05,919 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 13:46:05,922 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 13:46:05,958 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(AB,1)\n",
      "(CD,4)\n",
      "(EF,9)\n",
      "(GH,16)\n",
      "(IJ,25)\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "--\n",
    "-- registra las funciones en el script `pigudf.py`.\n",
    "--\n",
    "REGISTER /Users/jdvelasq/jython2.7.0/jython.jar\n",
    "REGISTER 'pigudf.py' using jython as myudf;\n",
    "\n",
    "u = LOAD 'udf.tsv' USING PigStorage()\n",
    "    AS (c1:CHARARRAY,\n",
    "        c2:CHARARRAY,\n",
    "        c3:INT);\n",
    "\n",
    "b = FOREACH u GENERATE myudf.concatenar(c1, c2), myudf.square(c3);\n",
    "DUMP b;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm pigudf.py pig_*  udf.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing transacciones.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile transacciones.txt\n",
    "1\t1\t1\t300\ta jumper\n",
    "2\t1\t2\t300\ta jumper\n",
    "3\t1\t2\t300\ta jumper\n",
    "4\t2\t3\t100\ta rubber chicken\n",
    "5\t1\t3\t300\ta jumper\n",
    "6\t1\t4\t300\ta jumper\n",
    "7\t1\t4\t250\ta jumper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing usuarios.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile usuarios.txt\n",
    "1\tmatthew@test.com\tEN\tUS\n",
    "2\tmatthew@test2.com\tEN\tGB\n",
    "3\tmatthew@test3.com\tFR\tFR\n",
    "4\tmatthew@test2.com\tES\tGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -put transacciones.txt\n",
    "!hadoop fs -put usuarios.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   1 root supergroup        141 2019-12-07 14:39 transacciones.txt\n",
      "-rw-r--r--   1 root supergroup        103 2019-12-07 14:39 usuarios.txt\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " u = LOAD 'usuarios.txt' USING PigStorage()\n",
      "    AS (userid:INT,\n",
      "        email:CHARARRAY,\n",
      "        lang:CHARARRAY,\n",
      "        location: CHARARRAY);\n",
      " t = LOAD 'transacciones.txt' USING PigStorage()\n",
      "    AS (tranid:INT,\n",
      "        prodid:INT,\n",
      "        userid:INT,\n",
      "        valorventa: INT,\n",
      "        nombre: CHARARRAY);\n",
      " TempR4 = JOIN u BY userid, t BY userid;\n",
      " r4 = FOREACH TempR4 GENERATE prodid, nombre, location;\n",
      " DUMP r4;\n",
      "2019-12-07 14:56:13,830 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 14:56:14,350 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 14:56:14,357 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2019-12-07 14:56:14,362 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2019-12-07 14:56:14,364 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2019-12-07 14:56:14,796 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2\n",
      "2019-12-07 14:56:14,809 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1575720238556_0010\n",
      "2019-12-07 14:56:14,811 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2019-12-07 14:56:14,831 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1575720238556_0010\n",
      "2019-12-07 14:56:14,836 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://3b2346cc720b:8088/proxy/application_1575720238556_0010/\n",
      "2019-12-07 14:56:29,938 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 14:56:29,947 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 14:56:30,039 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 14:56:30,043 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 14:56:30,065 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 14:56:30,069 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 14:56:30,092 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 14:56:30,095 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 14:56:30,127 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 14:56:30,134 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 14:56:30,154 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 14:56:30,156 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 14:56:30,182 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(1,a jumper,US)\n",
      "(1,a jumper,GB)\n",
      "(1,a jumper,GB)\n",
      "(1,a jumper,FR)\n",
      "(2,a rubber chicken,FR)\n",
      "(1,a jumper,GB)\n",
      "(1,a jumper,GB)\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "u = LOAD 'usuarios.txt' USING PigStorage()\n",
    "    AS (userid:INT,\n",
    "        email:CHARARRAY,\n",
    "        lang:CHARARRAY,\n",
    "        location: CHARARRAY);\n",
    "    \n",
    "t = LOAD 'transacciones.txt' USING PigStorage()\n",
    "    AS (tranid:INT,\n",
    "        prodid:INT,\n",
    "        userid:INT,\n",
    "        valorventa: INT,\n",
    "        nombre: CHARARRAY);\n",
    "\n",
    "TempR4 = JOIN u BY userid, t BY userid;\n",
    "r4 = FOREACH TempR4 GENERATE prodid, nombre, location;\n",
    "DUMP r4;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TempR5 = JOIN u BY userid, t BY userid;\n",
      " TempR5_2 = FOREACH TempR4 GENERATE location, valorventa;\n",
      " TempR5_3 = GROUP TempR5_2 BY location;\n",
      " r5 = FOREACH TempR5_3 GENERATE group, SUM(TempR5_2.valorventa);\n",
      " DUMP r5;\n",
      "2019-12-07 15:22:24,322 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:22:24,796 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:22:24,807 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2019-12-07 15:22:24,817 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2019-12-07 15:22:24,819 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2019-12-07 15:22:25,252 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2\n",
      "2019-12-07 15:22:25,273 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1575720238556_0011\n",
      "2019-12-07 15:22:25,275 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2019-12-07 15:22:25,288 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1575720238556_0011\n",
      "2019-12-07 15:22:25,290 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://3b2346cc720b:8088/proxy/application_1575720238556_0011/\n",
      "2019-12-07 15:22:40,379 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:22:40,385 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:22:40,442 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:22:40,445 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:22:40,480 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:22:40,485 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:22:41,807 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:22:41,818 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2019-12-07 15:22:41,823 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2019-12-07 15:22:42,257 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2019-12-07 15:22:42,270 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1575720238556_0012\n",
      "2019-12-07 15:22:42,272 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2019-12-07 15:22:42,287 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1575720238556_0012\n",
      "2019-12-07 15:22:42,291 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://3b2346cc720b:8088/proxy/application_1575720238556_0012/\n",
      "2019-12-07 15:23:02,413 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:23:02,421 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:23:02,466 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:23:02,468 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:23:02,484 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:23:02,485 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:23:03,012 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:23:03,014 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:23:03,032 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:23:03,034 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:23:03,048 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:23:03,049 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:23:03,063 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:23:03,065 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:23:03,079 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:23:03,081 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:23:03,096 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:23:03,098 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:23:03,115 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(FR,400)\n",
      "(GB,1150)\n",
      "(US,300)\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "TempR5 = JOIN u BY userid, t BY userid;\n",
    "TempR5_2 = FOREACH TempR5 GENERATE location, valorventa;\n",
    "TempR5_3 = GROUP TempR5_2 BY location;\n",
    "r5 = FOREACH TempR5_3 GENERATE group, SUM(TempR5_2.valorventa);\n",
    "DUMP r5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TempR5 = JOIN u BY userid, t BY userid;\n",
      " TempR5_2 = FOREACH TempR5 GENERATE lang,location, valorventa;\n",
      " TempR5_3 = GROUP TempR5_2 BY (lang,location);\n",
      " r5 = FOREACH TempR5_3 GENERATE group, SUM(TempR5_2.valorventa);\n",
      " DUMP r5;\n",
      "2019-12-07 15:42:10,155 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:42:11,442 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:42:11,454 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2019-12-07 15:42:11,463 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2019-12-07 15:42:11,466 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2019-12-07 15:42:11,906 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2\n",
      "2019-12-07 15:42:11,933 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1575720238556_0013\n",
      "2019-12-07 15:42:11,935 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2019-12-07 15:42:11,954 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1575720238556_0013\n",
      "2019-12-07 15:42:11,956 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://3b2346cc720b:8088/proxy/application_1575720238556_0013/\n",
      "2019-12-07 15:42:27,087 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:42:27,091 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:42:27,146 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:42:27,148 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:42:27,167 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:42:27,168 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:42:28,197 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:42:28,205 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2019-12-07 15:42:28,210 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2019-12-07 15:42:28,639 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2019-12-07 15:42:28,651 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1575720238556_0014\n",
      "2019-12-07 15:42:28,653 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2019-12-07 15:42:28,668 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1575720238556_0014\n",
      "2019-12-07 15:42:28,670 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://3b2346cc720b:8088/proxy/application_1575720238556_0014/\n",
      "2019-12-07 15:42:48,804 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:42:48,807 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:42:48,859 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:42:48,862 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:42:48,881 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:42:48,883 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:42:48,901 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:42:48,903 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:42:48,929 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:42:48,931 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:42:48,944 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:42:48,946 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:42:48,960 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:42:48,961 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:42:48,975 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:42:48,977 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:42:48,992 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:42:48,993 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:42:49,011 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "((EN,GB),600)\n",
      "((EN,US),300)\n",
      "((ES,GB),550)\n",
      "((FR,FR),400)\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "TempR5 = JOIN u BY userid, t BY userid;\n",
    "TempR5_2 = FOREACH TempR5 GENERATE lang,location, valorventa;\n",
    "TempR5_3 = GROUP TempR5_2 BY (lang,location);\n",
    "r5 = FOREACH TempR5_3 GENERATE group, SUM(TempR5_2.valorventa);\n",
    "DUMP r5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " r6 = FOREACH r5 GENERATE FLATTEN($0), $1;\n",
      " DUMP r6;\n",
      "2019-12-07 15:45:15,009 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:45:15,069 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:45:15,077 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2019-12-07 15:45:15,081 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2019-12-07 15:45:15,083 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2019-12-07 15:45:15,520 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2\n",
      "2019-12-07 15:45:15,536 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1575720238556_0015\n",
      "2019-12-07 15:45:15,541 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2019-12-07 15:45:15,760 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1575720238556_0015\n",
      "2019-12-07 15:45:15,761 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://3b2346cc720b:8088/proxy/application_1575720238556_0015/\n",
      "2019-12-07 15:45:30,846 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:45:30,853 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:45:30,901 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:45:30,904 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:45:30,922 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:45:30,925 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:45:31,828 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:45:31,836 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2019-12-07 15:45:31,844 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2019-12-07 15:45:31,860 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2019-12-07 15:45:31,874 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1575720238556_0016\n",
      "2019-12-07 15:45:31,876 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2019-12-07 15:45:32,112 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1575720238556_0016\n",
      "2019-12-07 15:45:32,116 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://3b2346cc720b:8088/proxy/application_1575720238556_0016/\n",
      "2019-12-07 15:45:52,450 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:45:52,454 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:45:52,508 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:45:52,511 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:45:52,529 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:45:52,545 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:45:52,565 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:45:52,566 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:45:52,581 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:45:52,583 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:45:52,599 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:45:52,601 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:45:52,615 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:45:52,617 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:45:52,630 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:45:52,633 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:45:52,648 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2019-12-07 15:45:52,650 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2019-12-07 15:45:52,665 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(EN,GB,600)\n",
      "(EN,US,300)\n",
      "(ES,GB,550)\n",
      "(FR,FR,400)\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "r6 = FOREACH r5 GENERATE FLATTEN($0), $1;\n",
    "DUMP r6;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ejercicio2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ejercicio2.py\n",
    "\n",
    "#from pig_util import outputSchema\n",
    "\n",
    "@outputSchema(\"as:int\")\n",
    "def impuestos(pais, valorven):\n",
    "    if pais == None:\n",
    "        return None\n",
    "    if pais == 'US':\n",
    "        return valorven * 0.08\n",
    "    if pais == 'FR':\n",
    "        return valorven * 0.12\n",
    "    if pais == 'GB':\n",
    "        return valorven * 0.18\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DESCRIBE u;\n",
      "u: {\n",
      "    userid: int,\n",
      "    email: chararray,\n",
      "    lang: chararray,\n",
      "    location: chararray\n",
      "}\n",
      " DESCRIBE t;\n",
      "t: {\n",
      "    tranid: int,\n",
      "    prodid: int,\n",
      "    userid: int,\n",
      "    valorventa: int,\n",
      "    nombre: chararray\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "DESCRIBE u;\n",
    "DESCRIBE t;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REGISTER /Users/jdvelasq/jython2.7.0/jython.jar\n",
      "2019-12-07 16:18:51,685 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 101: file '/Users/jdvelasq/jython2.7.0/jython.jar' does not exist.\n",
      "Details at logfile: /datalake/pig_1575730367516.log\n",
      " REGISTER 'ejercicio2.py' using jython as myudf2;\n",
      " TempR5 = JOIN u BY userid, t BY userid;\n",
      " TempR5_2 = FOREACH TempR5 GENERATE tranid,nombre,location, valorventa;\n",
      " tmpR7 = FOREACH TempR5_2 GENERATE trainid,nombre,valorventa,\n",
      "myudf2.impuestos(location, valorventa) as valorimpuestos,\n",
      "valorventa+myudf2.impuestos(location, valorventa) as valortotal;\n",
      "2019-12-07 16:18:52,263 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 1025: <line 83, column 34> Invalid field projection. Projected field [trainid] does not exist in schema: t::tranid:int,t::nombre:chararray,u::location:chararray,t::valorventa:int.\n",
      "Details at logfile: /datalake/pig_1575730367516.log\n",
      " DUMP tmpR7;\n",
      "2019-12-07 16:18:52,345 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 1003: Unable to find an operator for alias tmpR7\n",
      "Details at logfile: /datalake/pig_1575730367516.log\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "REGISTER /Users/jdvelasq/jython2.7.0/jython.jar\n",
    "REGISTER 'ejercicio2.py' using jython as myudf2;\n",
    "\n",
    "TempR5 = JOIN u BY userid, t BY userid;\n",
    "TempR5_2 = FOREACH TempR5 GENERATE tranid,nombre,location, valorventa;\n",
    "tmpR7 = FOREACH TempR5_2 GENERATE trainid,nombre,valorventa,myudf2.impuestos(location, valorventa) as valorimpuestos,valorventa+myudf2.impuestos(location, valorventa) as valortotal;\n",
    "DUMP tmpR7;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
