{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext bigdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%hive_start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeout 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Se crea el directorio wordcount en la carpeta actual de trabajo\n",
    "## y se escriben tres archivos en ella.\n",
    "##\n",
    "!mkdir -p wordcount/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A continuación se generan tres archivos de prueba que se almacenan en la carpeta wordcount/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing wordcount/text0.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile wordcount/text0.txt\n",
    "Analytics is the discovery, interpretation, and communication of meaningful patterns\n",
    "in data. Especially valuable in areas rich with recorded information, analytics relies\n",
    "on the simultaneous application of statistics, computer programming and operations research\n",
    "to quantify performance.\n",
    "\n",
    "Organizations may apply analytics to business data to describe, predict, and improve business\n",
    "performance. Specifically, areas within analytics include predictive analytics, prescriptive\n",
    "analytics, enterprise decision management, descriptive analytics, cognitive analytics, Big\n",
    "Data Analytics, retail analytics, store assortment and stock-keeping unit optimization,\n",
    "marketing optimization and marketing mix modeling, web analytics, call analytics, speech\n",
    "analytics, sales force sizing and optimization, price and promotion modeling, predictive\n",
    "science, credit risk analysis, and fraud analytics. Since analytics can require extensive\n",
    "computation (see big data), the algorithms and software used for analytics harness the most\n",
    "current methods in computer science, statistics, and mathematics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing wordcount/text1.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile wordcount/text1.txt\n",
    "The field of data analysis. Analytics often involves studying past historical data to\n",
    "research potential trends, to analyze the effects of certain decisions or events, or to\n",
    "evaluate the performance of a given tool or scenario. The goal of analytics is to improve\n",
    "the business by gaining knowledge which can be used to make improvements or changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing wordcount/text2.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile wordcount/text2.txt\n",
    "Data analytics (DA) is the process of examining data sets in order to draw conclusions\n",
    "about the information they contain, increasingly with the aid of specialized systems\n",
    "and software. Data analytics technologies and techniques are widely used in commercial\n",
    "industries to enable organizations to make more-informed business decisions and by\n",
    "scientists and researchers to verify or disprove scientific models, theories and\n",
    "hypotheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## En esta aplicación se usarán dos tablas:\n",
    "##   docs: para cargar el contenido de los archivos de texto, donde cada línea equivale a un registro.\n",
    "##   word_counts: En donde aparece cada palabra y su respectivo conteo.\n",
    "## A continuación se elimnan dichas tablas si existen en el sistema, y luego se crea la tabla docs con un solo campo del tipo STRING."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP TABLE IF EXISTS docs;\n",
      "OK\n",
      "Time taken: 12.205 seconds\n",
      "DROP TABLE IF EXISTS word_counts;\n",
      "OK\n",
      "Time taken: 0.013 seconds\n",
      "CREATE TABLE docs (line STRING);\n",
      "OK\n",
      "Time taken: 1.229 seconds\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "DROP TABLE IF EXISTS docs;\n",
    "DROP TABLE IF EXISTS word_counts;\n",
    "CREATE TABLE docs (line STRING);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## En el siguiente código, se hace la carga directa de todos los archivos que se encuentran en el directorio wordcount en la tabla docs. Luego, se imprimen los primeros cinco registros de la tabla para verificar que la lectura fue correcta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD DATA LOCAL INPATH \"wordcount/\" OVERWRITE INTO TABLE docs;\n",
      "Loading data to table default.docs\n",
      "OK\n",
      "Time taken: 2.679 seconds\n",
      "SELECT * FROM docs LIMIT 5;\n",
      "OK\n",
      "Analytics is the discovery, interpretation, and communication of meaningful patterns\n",
      "in data. Especially valuable in areas rich with recorded information, analytics relies\n",
      "on the simultaneous application of statistics, computer programming and operations research\n",
      "to quantify performance.\n",
      "\n",
      "Time taken: 2.331 seconds, Fetched: 5 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "LOAD DATA LOCAL INPATH \"wordcount/\" OVERWRITE INTO TABLE docs;\n",
    "SELECT * FROM docs LIMIT 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Una vez cargados los archivos, se procede a partir las líneas por palabras, usando la función split(line, '\\\\s'); \n",
    "## la expresión \\\\s indica que se realice la partición por los espacios en blanco; de esta forma, split() genera una lista de palabras. \n",
    "## La función explode(.) de Hive en conjunto con SELECT, genera un nuevo registro por cada palabra en line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT explode(split(line, '\\\\s')) AS word FROM docs LIMIT 5;\n",
      "OK\n",
      "Analytics\n",
      "is\n",
      "the\n",
      "discovery,\n",
      "interpretation,\n",
      "Time taken: 0.603 seconds, Fetched: 5 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "SELECT explode(split(line, '\\\\s')) AS word FROM docs LIMIT 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Para realizar el conteo, la expresión SELECT word, count(1) AS count ... GROUP BY word genera una tabla con dos columnas, \n",
    "##  donde la primera columna (word) correspodne a cada palabra en el texto, y la segunda columna representa la cantidad de veces que aparece en los registros generados \n",
    "##  por la expresión SELECT explode(split(line, '\\\\s')) AS word FROM docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE word_counts\n",
      "AS\n",
      "    SELECT word, count(1) AS count\n",
      "    FROM\n",
      "        (SELECT explode(split(line, '\\\\s')) AS word FROM docs) w\n",
      "GROUP BY\n",
      "    word\n",
      "ORDER BY\n",
      "    word;\n",
      "WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.\n",
      "Query ID = root_20191127201718_42add91d-6b46-41ad-a705-27d2ab07fae8\n",
      "Total jobs = 2\n",
      "Launching Job 1 out of 2\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1574885052112_0001, Tracking URL = http://499bf3956267:8088/proxy/application_1574885052112_0001/\n",
      "Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1574885052112_0001\n",
      "Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "2019-11-27 20:17:34,770 Stage-1 map = 0%,  reduce = 0%\n",
      "2019-11-27 20:17:41,587 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 3.71 sec\n",
      "2019-11-27 20:17:49,372 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 6.51 sec\n",
      "MapReduce Total cumulative CPU time: 6 seconds 510 msec\n",
      "Ended Job = job_1574885052112_0001\n",
      "Launching Job 2 out of 2\n",
      "Number of reduce tasks determined at compile time: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1574885052112_0002, Tracking URL = http://499bf3956267:8088/proxy/application_1574885052112_0002/\n",
      "Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1574885052112_0002\n",
      "Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "2019-11-27 20:18:04,605 Stage-2 map = 0%,  reduce = 0%\n",
      "2019-11-27 20:18:11,167 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 1.94 sec\n",
      "2019-11-27 20:18:18,878 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 4.37 sec\n",
      "MapReduce Total cumulative CPU time: 4 seconds 370 msec\n",
      "Ended Job = job_1574885052112_0002\n",
      "Moving data to directory hdfs://0.0.0.0:9000/user/hive/warehouse/word_counts\n",
      "MapReduce Jobs Launched: \n",
      "Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 6.51 sec   HDFS Read: 10186 HDFS Write: 4345 SUCCESS\n",
      "Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 4.37 sec   HDFS Read: 9498 HDFS Write: 1730 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 10 seconds 880 msec\n",
      "OK\n",
      "Time taken: 62.141 seconds\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "CREATE TABLE word_counts\n",
    "AS\n",
    "    SELECT word, count(1) AS count\n",
    "    FROM\n",
    "        (SELECT explode(split(line, '\\\\s')) AS word FROM docs) w\n",
    "GROUP BY\n",
    "    word\n",
    "ORDER BY\n",
    "    word;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Para visualizar los resultados obtenidos, se realiza un SELECT sobre la tabla word_counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM word_counts LIMIT 10;\n",
      "OK\n",
      "\t1\n",
      "(DA)\t1\n",
      "(see\t1\n",
      "Analytics\t2\n",
      "Analytics,\t1\n",
      "Big\t1\n",
      "Data\t3\n",
      "Especially\t1\n",
      "Organizations\t1\n",
      "Since\t1\n",
      "Time taken: 0.218 seconds, Fetched: 10 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "SELECT * FROM word_counts LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finalmente, y una vez se ha terminado de depurar el código, se cierra el interprete de Hive que se abrió en el background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%hive_quit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
